# Introduction

According to the central limit theorem, every sequence of normalized and centered sums of independent random variables converges in distribution as the number of terms in the sum increases unboundedly, to a normal random variable, provided Lindeberg's conditions are fulfilled. In other words, the sum of a large number of independent random variables is as a rule approximately normal. 

Under what conditions is this sum exactly normal? It turns out that this is the case only when each of the summands is normal. This result, conjectured by Paul Levy and proved in 1936 by Cramer, gave birth to a new field of probability theory-decompositions of random variables into independent components. A rigorous formulation of the problem is as follows. Call a random variable Xl a component of a random variable X if there exists a random variable X 2 such that Xl and X 2 are independent and 

<pre>
X = X1 +X2                  (0.1) 
</pre>

Problem: given a random variable X, characterize the set of all its components as thoroughly as possible. 

If the condition that Xl and X 2 be independent is dropped, the problem becomes meaningless, since then Xl may be chosen arbitrarily and (0.1) will hold with X2 = X - Xl. The independence condition may impose considerable restrictions on the form of the components. Thus, it follows from the above-mentioned result of Cramer that all the components of a normal variable are normal. 

The years 1937 and 1938 saw intensive work in the theory of decompositions of random variables on the part of Levy, Khinchine and Raikov, who established several fundamental results. Analogies between this theory and arithmetic were observed. It was found that there exist indecomposable random variables, reminiscent of prime numbers. In contradistinction to arithmetic, however, not every random variable has an indecomposable component. Khinchine proved an analog of the fundamental theorem of arithmetic: every random variable which has an indecomposable component is the sum of two indecomposable random variables, one of which has no indecomposable components while the other is the sum of fmitely or countably many independent indecomposable components. 

This decomposition is as a rule not unique. Khinchine also showed that the class of random variables with no indecomposable components (now denoted by 1 0 ) is a proper subclass of the class of infinitely divisible random variables. This raised the question of finding conditions distinguishing 10 as a subclass of the class of infinitely divisible random variables. 
After a twenty year break, interest in decompositions of random variables was revived. At the end of the fifties, various studies of the class 1 0 developed ideas establishing deep connections of the problem to the theory of entire functions. These ideas proved highly fruitful and were the basis for many and diverse investigations. 
The "state of the art" in decompositions of random variables prior to 1960 is reflected in the monograph of Linnik [1]. 

...

In the present monograph we have striven to describe as thoroughly as possible the state of the art of the theory as of 1971, though we cannot, of course, lay claim to completeness. In particular, no consideration is given to two theories intimately bound up with decompositions of random variables and vectors-the delphic semigroups of Kendall [3] and the generalized convolutions of Urbanik [4]. 

...

[1] Ju.V. Linnik, __*Decompositions of probability distributions*__, Izdat. Leningrad. Univ., Lenlngrad, 1960; English translation: Dover, New, York; Oliver & Boyd, London, 1964. 

[2] Ju.V. Linnik, I.V. Ostrovskii, __*Decomposition of Random Variables and Vectors*__, American Mathematical Society, 1977

[3] David G. Kendall, __*Delphic semi-groups, infinitely divisible regenerative phenomena, and the arithmetic 
of p-functions*__, z. Wahrscheinlichkeitstheorie und Verw. Gebiete 9 (1968), 163-195. 

[4] K. Urbanik, __*Generalized convolutions*__, Studia Math. 23 (1963/64), 217-245. 
