# Introduction

According to the central limit theorem, every sequence of normalized and centered sums of independent random variables converges in distribution as the number of terms in the sum increases unboundedly, to a normal random variable, provided Lindeberg's conditions are fulfilled. In other words, the sum of a large number of independent random variables is as a rule approximately normal. 

Under what conditions is this sum exactly normal? It turns out that this is the case only when each of the summands is normal. This result, conjectured by Paul Levy and proved in 1936 by Cramer, gave birth to a new field of probability theory-decompositions of random variables into independent components. A rigorous formulation of the problem is as follows. Call a random variable Xl a component of a random variable X if there exists a random variable X 2 such that Xl and X 2 are independent and 

X = X1 +X2       (0.1) 

Problem: given a random variable X, characterize the set of all its components as 
thoroughly as possible. 

If the condition that Xl and X 2 be independent is dropped, the problem 
becomes meaningless, since then Xl may be chosen arbitrarily and (0.1) will hold 
with X2 = X - Xl. The independence condition may impose considerable re- 
strictions on the form of the components. Thus, it follows from the above-men- 
tioned result of Cramer that all the components of a normal variable are normal. 

Ju.V. Linnik, I.V. Ostrovskii, __*Decomposition of Random Variables and Vectors*__, American Mathematical Society, 1977
